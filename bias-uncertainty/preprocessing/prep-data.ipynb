{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cf9f75",
   "metadata": {},
   "source": [
    "# Compute model bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ca268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import simplejson\n",
    "import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee57e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(name, out):\n",
    "    with open(f\"../data/{name}.json\", \"w\") as f:\n",
    "        simplejson.dump(out, f, sort_keys=True, ignore_nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9524c2",
   "metadata": {},
   "source": [
    "## Reference data\n",
    "\n",
    "### E-OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_tas = xr.open_dataset(\"reference/tg_ens_mean_0.1deg_reg_v30.0e_REMAP_MEAN_1971-2000.nc\")\n",
    "eobs_tas = (eobs_tas[\"tg\"] + 273.15).squeeze(drop=True)  # convert to kelvin\n",
    "\n",
    "eobs_tas_var = xr.open_dataset(\"reference/tg_ens_mean_0.1deg_reg_v30.0e_REMAP_VAR_1971-2000.nc\")\n",
    "eobs_tas_var = eobs_tas_var[\"tg\"].squeeze(drop=True)\n",
    "\n",
    "eobs_pr = xr.open_dataset(\"reference/rr_ens_mean_0.1deg_reg_v30.0e_REMAP_MEAN_YEARSUM_1971-2000.nc\")\n",
    "eobs_pr = eobs_pr[\"rr\"].squeeze(drop=True)\n",
    "\n",
    "eobs_pr_var = xr.open_dataset(\"reference/rr_ens_mean_0.1deg_reg_v30.0e_REMAP_VAR_YEARSUM_1971-2000.nc\")\n",
    "eobs_pr_var = eobs_pr_var[\"rr\"].squeeze(drop=True)\n",
    "\n",
    "eobs = xr.merge([\n",
    "    eobs_tas.rename(\"tas\"),\n",
    "    eobs_pr.rename(\"pr\"),\n",
    "    eobs_tas_var.rename(\"tas_var\"),\n",
    "    eobs_pr_var.rename(\"pr_var\")\n",
    "]).rio.write_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd6290",
   "metadata": {},
   "source": [
    "### ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b617ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_tas = xr.open_dataset(\"reference/era5_1971_2000_tas_MEAN_REMAP.nc\")\n",
    "era5_tas = era5_tas[\"t2m\"].squeeze(drop=True)\n",
    "\n",
    "era5_tas_var = xr.open_dataset(\"reference/era5_1971_2000_tas_VAR_REMAP.nc\")\n",
    "era5_tas_var = era5_tas_var[\"t2m\"].squeeze(drop=True)\n",
    "\n",
    "era5_pr = xr.open_dataset(\"reference/era5_1971_2000_total_precip_YEARSUM_REMAP.nc\")\n",
    "era5_pr = era5_pr[\"tp\"].squeeze(drop=True)\n",
    "\n",
    "era5_pr_var = xr.open_dataset(\"reference/era5_1971_2000_total_precip_VAR_YEARSUM_REMAP.nc\")\n",
    "era5_pr_var = era5_pr_var[\"tp\"].squeeze(drop=True)\n",
    "\n",
    "era5 = xr.merge([\n",
    "    era5_tas.rename(\"tas\"),\n",
    "    era5_pr.rename(\"pr\"),\n",
    "    era5_tas_var.rename(\"tas_var\"),\n",
    "    era5_pr_var.rename(\"pr_var\")\n",
    "]).rio.write_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7948f16",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac40457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    name, _ = os.path.splitext(os.path.basename(ds.encoding[\"source\"]))\n",
    "    _, _, gcm, _, ens, rcm, *_ = name.split(\"_\")\n",
    "    ds = ds.drop_vars(['time', 'time_bnds'])\n",
    "    ds =  ds.expand_dims({\"model\": [f\"{gcm} {rcm} {ens}\"]})\n",
    "    if \"height\" in ds.coords:\n",
    "        ds = ds.drop_vars(['height'])\n",
    "    return ds\n",
    "\n",
    "models = xr.open_mfdataset(\"models-hist/*1971_2000*.nc4\", preprocess=preprocess).squeeze().load()\n",
    "models[\"pr\"] = models[\"pr\"] * 86400.\n",
    "models = models.rio.write_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "export(\"metadata\", {\n",
    "    \"models\": [dict(zip([\"gcm\", \"rcm\", \"ens\"], m.split(\" \"))) for m in models[\"model\"].values],\n",
    "    \"attrs\": {\n",
    "        \"pr\": {\n",
    "            \"name\": \"precipitation\",\n",
    "            \"bias\": {\n",
    "                \"unit\": \"%\",\n",
    "                \"period\": \"1971-2000\"\n",
    "            }\n",
    "        },\n",
    "        \"tas\": {\n",
    "            \"name\": \"temperature\",\n",
    "            \"bias\": {\n",
    "                \"unit\": \"Â°C\",\n",
    "                \"period\": \"1971-2000\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93232410",
   "metadata": {},
   "source": [
    "## Zonal statistics of bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a34df",
   "metadata": {},
   "source": [
    "\n",
    "Run the regions-euro-cordex notebook to generate the regions file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c978670",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = gpd.read_file(\"../data/regions.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal_stats(bias, regions, func):\n",
    "    return {\n",
    "        nuts_id: func(bias.rio.clip([region.geometry], all_touched=True))\n",
    "        for nuts_id, region in tqdm.tqdm(regions.set_index(\"id\").iterrows())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(ref):\n",
    "    \"\"\"Bias as (model - reference)\"\"\"\n",
    "    return xr.Dataset({\n",
    "        \"tas\": (models[\"tas\"] - ref[\"tas\"]),\n",
    "        \"pr\": (models[\"pr\"] - ref[\"pr\"] + 0.00001) / (ref[\"pr\"] + 0.00001) * 100.  # in percent\n",
    "    })\n",
    "\n",
    "def weighted_median(data):\n",
    "    area_weights = np.cos(np.deg2rad(data[\"latitude\"]))\n",
    "    median = data.weighted(area_weights).quantile(0.5, dim=[\"latitude\", \"longitude\"])\n",
    "    return {\n",
    "        \"tas\": median[\"tas\"].values.round(3).tolist(),\n",
    "        \"pr\": median[\"pr\"].values.round(2).tolist()\n",
    "    }\n",
    "\n",
    "bias_era5 = zonal_stats(bias(era5), regions, weighted_median)\n",
    "bias_eobs = zonal_stats(bias(eobs), regions, weighted_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank model by total bias (all variables), combine biases with method of\n",
    "# Reichler and Kim (2008), BAMS.\n",
    "\n",
    "# TODO This implementation is not consistent with the computation of bias above as it rather\n",
    "# considers \"error\", i.e. bias independent of sign without the possibility of \"compensation\"\n",
    "# during the spatial aggregation. It also need adapting to the use of the median in the\n",
    "# spatial aggreation used for the bias values.\n",
    "\n",
    "def normalized_error(ref):\n",
    "    return xr.Dataset({\n",
    "        # Equation (1), inner\n",
    "        v: (models[v] - ref[v])**2 / ref[v + \"_var\"]\n",
    "        for v in [\"tas\", \"pr\"]\n",
    "    })\n",
    "\n",
    "def rank(data):\n",
    "    return {}  # TODO omit until we've figured out the consistency issues\n",
    "    area_weights = np.cos(np.deg2rad(data[\"latitude\"]))\n",
    "    # Equation (1) outer (weighted sum)\n",
    "    e2vm = data.weighted(area_weights).sum(dim=[\"latitude\", \"longitude\"])\n",
    "    # Equation (2)\n",
    "    i2vm = e2vm / e2vm.mean(dim=\"model\")\n",
    "    # Equation (3)\n",
    "    i2m = 0.5 * (i2vm[\"tas\"].values + i2vm[\"pr\"].values)\n",
    "    # Save ranks rather than I2m values (more compact in output)\n",
    "    return {\"rank\": i2m.argsort().argsort().tolist()}\n",
    "\n",
    "rank_era5 = zonal_stats(normalized_error(era5), regions, rank)\n",
    "rank_eobs = zonal_stats(normalized_error(eobs), regions, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7848a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "export(\"bias-era5\", {key: {**bias_era5[key], **rank_era5[key]} for key in bias_era5.keys()})\n",
    "export(\"bias-eobs\", {key: {**bias_eobs[key], **rank_eobs[key]} for key in bias_eobs.keys()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climaax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
